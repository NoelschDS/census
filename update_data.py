# -*- coding: utf-8 -*-
"""Update_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KOKI9nSSSKC18H32JVtfYXEeKIFarASY
"""

import requests
import json
import pandas as pd
from datetime import datetime

def make_call(year, mon, vars, key="&key=3a9f008a5485a325fc9a459873d07294a071e184"):
  #https://api.census.gov/data/2024/cps/basic/jan?get=PEMLR,PWSSWGT,PEMARITL&for=state:01&PEEDUCA=39
  url = "https://api.census.gov/data/"
  year = f"{year}"
  mon = f"{mon}"
  dataset = "/cps/basic/"
  get = "?get="
  vars = f"{vars}"
  predicate = "&for="
  geog =  "state"

  return url + year + dataset + mon + get + vars + predicate + geog + key

#Variable list
#STATE - FIPS STATE Code
#GTCBASZ - Metropolitan Statistical Area Size
#GTMETSTA - Metropolitan Status
#PRTAGE - Demographics - age topcoded at 85, 90 or 80 (see full description)
#PEDISDRS - Disability - Difficulty dressing or bathing
#PEDISEAR - Disability - Deaf or serious difficulty hearing
#PEDISEYE - Disability - Blind or difficulty seeing even with glasses
#PEDISOUT - Disability - Difficulty doing errands
#PEDISPHY - Disability - Difficulty walking or climbing stairs
#PEDISREM - Disability - Difficulty remembering or making decisions
#HEHOUSUT - Household-type of living quarters
#HETENURE - Household-own/rent living quarters
#HRNUMHOU - Household-total # of members
#HRHTYPE - Household-type of family/single individual
#CBSA - #HRHTYPE - Household-type of family/single individual
vars = "CBSA,GTMETSTA,GTCBSASZ,PRTAGE,PEDISDRS,PEDISEAR,PEDISEYE,PEDISOUT,PEDISPHY,PEDISREM,HEHOUSUT,HETENURE,HRNUMHOU,HRHTYPE"
var_list = vars.split(",")

#Store current year
this_year = datetime.now().year

#Make API call
dat = requests.get(make_call(this_year, "mar", vars)).text

#Investigate list of results
results = json.loads(dat)

#Create a dataframe for the results
df=pd.DataFrame(results[1:], columns=results[0])

#Get Dictionary for vars
def retrieve_dictionaries(year, mon, vars, key="&key=3a9f008a5485a325fc9a459873d07294a071e184"):
  #https://api.census.gov/data/2024/cps/basic/mar/variables/CBSA.json
  url = "https://api.census.gov/data/"
  year = f"{year}"
  dataset = "/cps/basic/"
  mon = f"{mon}"
  variables = "/variables/"
  vars = f"{vars}"
  end = ".json"

  return url + year + dataset + mon + variables + vars + end

def list_dictionaries(year, mon, var_list):
  var_map = {}
  for var in var_list:
    var_map[var] = var
    try:
      if "range" in json.loads(requests.get(retrieve_dictionaries(year, mon, var)).text)['values'].keys():
        var_map[var] = json.loads(requests.get(retrieve_dictionaries(year, mon, var)).text)['values']['range']
      else:
        var_map[var] = json.loads(requests.get(retrieve_dictionaries(year, mon, var)).text)['values']['item']
    except:
      var_map[var] = "Dictionary Not Found"
  return var_map

ref = list_dictionaries(2024, "mar", var_list)

#Map values from df to dictionary values
df_values = df.copy()
for col in df.columns:
  try:
    df_values[col] = df[col].map(ref[col])
  except:
    pass
try:
  df_values=df_values.rename(columns={'CBSA':'GTCBSA'})
except:
  raise RuntimeError("No CBSA Column")
df_values['year'] = f'{this_year}'

df_values

#Make Disability Features Dummy Variables
dummy_var=pd.get_dummies(df[['PEDISDRS', 'PEDISEAR', 'PEDISEYE', 'PEDISOUT', 'PEDISPHY', 'PEDISREM', 'HEHOUSUT', 'HETENURE','HRHTYPE']]).astype(int)

#Add Dummy Variables to df_values
df_with_dummy = pd.concat([df_values, dummy_var], axis=1)

#Group Dummy Variables
#By Rent
df_by_rent = df_with_dummy.groupby(["state", "GTCBSA", "year", 'HETENURE'])[dummy_var.columns].sum()
df_by_rent.reset_index(inplace=True)
melt_rent_data=df_by_rent.melt(id_vars=["state", "GTCBSA", "year", 'HETENURE'])

#By Type
df_by_type = df_with_dummy.groupby(["state", "GTCBSA", "year", 'HRHTYPE'])[dummy_var.columns].sum()
df_by_type.reset_index(inplace=True)
melt_type_data=df_by_type.melt(id_vars=["state", "GTCBSA", "year", 'HRHTYPE'])

rent_data = pd.read_csv("rent_data.csv", index_col=0)
type_data = pd.read_csv("type_data.csv", index_col=0)

rent_data

melt_rent_data

rent_data=pd.concat([rent_data, melt_rent_data]).drop_duplicates()
type_data=pd.concat([type_data, melt_type_data]).drop_duplicates()

rent_data=rent_data[rent_data['variable'].str.contains('Yes')]
type_data=type_data[type_data['variable'].str.contains('Yes')]

rent_data.to_csv("rent_data.csv")
type_data.to_csv("type_data.csv")

from github import Github

# Authentication is defined via github.Auth
from github import Auth

# using an access token
auth = Auth.Token("access_token")

# First create a Github instance:

# Public Web Github
g = Github(auth=auth)

# Github Enterprise with custom hostname
g = Github(base_url="https://NoelschDS/api/v3", auth=auth)

# Then play with your Github objects:
for repo in g.get_user().get_repos():
    print(repo.name)

# To close connections after use
g.close()